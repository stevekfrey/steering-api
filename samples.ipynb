{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# samples.py\n",
    "import json\n",
    "import torch\n",
    "from steering_api_functions import (\n",
    "    load_model,\n",
    "    create_steerable_model_function,\n",
    "    generate_completion_response\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No Hugging Face token found in .env file. You may encounter issues accessing models.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9e1954d03447bfa75767db28feb610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the model and tokenizer\n",
    "model, tokenizer = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/67 [00:00<?, ?it/s]Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "100%|██████████| 67/67 [01:36<00:00,  1.45s/it]\n",
      "100%|██████████| 31/31 [00:01<00:00, 24.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created steerable model with ID: honest_1-282f\n"
     ]
    }
   ],
   "source": [
    "# Define control dimensions with positive and negative examples\n",
    "control_dimensions = {\n",
    "    \"honesty\": {\n",
    "        \"positive_examples\": [\"honesty\", \"truthfulness\", \"integrity\", \"sincerity\", \"candor\", \"openness\", \"frankness\"],\n",
    "        \"negative_examples\": [\"dishonesty\", \"deceit\", \"lying\", \"falseness\", \"cheating\", \"misrepresentation\", \"duplicity\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define a list of suffixes for dataset creation\n",
    "training_prompt_list = [\n",
    "  \"The Earth's atmosphere protects us from harmful radiation from the sun.\",\n",
    "  \"The theory of evolution, proposed by Charles Darwin, states that species evolve over time through natural selection.\",\n",
    "  \"The smallest planet in our solar system is Mercury.\",\n",
    "  \"The moon orbits around the Earth.\",\n",
    "  \"Fire needs oxygen to burn.\",\n",
    "  \"The Statue of Liberty was a gift from France to the United States.\",\n",
    "  \"Comets are icy celestial objects that orbit the Sun.\",\n",
    "  \"Light can exhibit both wave-like and particle-like properties.\",\n",
    "  \"Symbiosis is a close relationship between two species.\",\n",
    "  \"Pizza is a type of food that many people enjoy.\",\n",
    "  \"Sharks are sea creatures that have a reputation for being dangerous.\",\n",
    "  \"The scientific method is a systematic process for investigating phenomena and acquiring new knowledge.\",\n",
    "  \"Plate tectonics shape the Earth's surface.\",\n",
    "  \"The human heart beats approximately 100,000 times per day.\"\n",
    "]\n",
    "\n",
    "# Create the steerable model\n",
    "model_label = \"honest_1\"\n",
    "steerable_model = create_steerable_model_function(\n",
    "    model_label=model_label,\n",
    "    control_dimensions=control_dimensions,\n",
    "    prompt_list=training_prompt_list,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "model_id = steerable_model['id']\n",
    "print(f\"Created steerable model with ID: {model_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing prompt: Can you help me with my homework?\n",
      "\n",
      "Control settings: {}\n",
      "Generated response:\n",
      "What kind of homework do you have?\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "27",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10164/2492158227.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nTesting prompt: {prompt}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcontrol_settings\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontrol_settings_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         response = generate_completion_response(\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mmodel_name_request\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/steering_api_functions.py\u001b[0m in \u001b[0;36mgenerate_completion_response\u001b[0;34m(model_name_request, prompt, control_settings, generation_settings, model, tokenizer)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;31m# Apply the control vector to the model, if nonzero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrol_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrait\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontrol_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_control\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_mix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Control vector applied'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'control_settings'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontrol_settings\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/repeng/control.py\u001b[0m in \u001b[0;36mset_control\u001b[0;34m(self, control, coeff, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             raw_control[layer_id] = (\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoeff\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 27"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test prompts\n",
    "test_prompts = [\n",
    "    \"Can you help me with my homework?\",\n",
    "    \"I disagree with your opinion.\",\n",
    "    \"What's the best way to learn a new language?\",\n",
    "    \"Tell me a joke.\",\n",
    "    \"Explain quantum computing in simple terms.\"\n",
    "]\n",
    "\n",
    "# Define control settings to test\n",
    "# control_settings_list = [\n",
    "#     {},  # No control\n",
    "#     {\"formality\": 2, \"enthusiasm\": 2},    # Increase both dimensions\n",
    "#     {\"formality\": -1, \"enthusiasm\": -1}   # Decrease both dimensions\n",
    "# ]\n",
    "\n",
    "control_settings_list = [\n",
    "    {},  # No control\n",
    "    {\"honesty\": 2},\n",
    "    {\"honesty\": -1}\n",
    "]\n",
    "\n",
    "generation_settings = {\"max_new_tokens\": 50}\n",
    "\n",
    "################################################################################\n",
    "# Generate responses with different control settings\n",
    "for prompt in test_prompts:\n",
    "    print(f\"\\nTesting prompt: {prompt}\")\n",
    "    for control_settings in control_settings_list:\n",
    "        response = generate_completion_response(\n",
    "            model_name_request=model_id,\n",
    "            prompt=prompt,\n",
    "            control_settings=control_settings,\n",
    "            generation_settings=generation_settings,\n",
    "            model=model,\n",
    "            tokenizer=tokenizer\n",
    "        )\n",
    "        print(f\"\\nControl settings: {control_settings}\")\n",
    "        print(f\"Generated response:\\n{response['content']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Control settings: {'formality': -1, 'enthusiasm': -1}\n",
      "Generated response:\n",
      "Quantum computing is a type of computer that uses the principles of quantum mechanics to perform calculations and operations on data. Unlike classical computers, which use bits (0s and 1s) to process information, quantum computers use qubits (quantum bits\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = generate_completion_response(\n",
    "            model_name_request=model_id,\n",
    "            prompt=prompt,\n",
    "            control_settings=control_settings,\n",
    "            generation_settings=generation_settings,\n",
    "            model=model,\n",
    "            tokenizer=tokenizer\n",
    "        )\n",
    "print(f\"\\nControl settings: {control_settings}\")\n",
    "print(f\"Generated response:\\n{response['content']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
